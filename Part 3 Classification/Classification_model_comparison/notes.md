
```python

  * Logistic Regression:
 
    Pros:
        given information about statistical significance of features
        
    Cons:
        logistic regression assumptions
        
  
  * KNN: K-nearest neighbor
  
    Pros:
       fast and efficient
    
    Cons:
       need to pick the number of neighbors K
       
  * SVM:
    
    Pros:
       not biased by outliers and not sensitive to overfit
       
    Cons:
       not fit for non-linear problems and not best choice for large number of features
  
  
  * Kernel SVM:
    
    Pros:
       high performance on non-linear problems, not biased by outliers, not sensitive to overfit
       
    Cons:
       not best choice for large number of features
  
  * Naive Bayes:
    
    Pros:
      not affect by outliers, work on non-linear problems
     
    Cons:
      "Naive" assumption may not always true
      
  * Decision Tree:
    
    Pros:
       no need for feature scaling and work on both linear/non-linear problems
    
    Cons:
       poor results on small datasets and overfit may occur 
       
  * Random Forest:
   
    Pros:
       work for both linear and non-linear problems
    
    Cons:
       overfit can occur and need to pick numbers of trees 
      
        
        
        










```
